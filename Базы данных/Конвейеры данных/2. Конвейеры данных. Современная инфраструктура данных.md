Прежде чем принимать решение о составе и устройстве будущего конвейера необходимо понимать из чего состоит современный стек данных. Имеются базовые потребности, которые стали отраслевыми стандартами:
- облачные хранилища и озера данных;
- инструменты сбора данных;
- разнообразие источников данных;
- платформы оркестровки процессов;
- фреймворки и инструменты моделирования;

# Пример аналитики
БД постгресс с данными покупателя, сторонний инструмент Google Analytics для отслеживания функционирования сайта позволяет понять контекст как пользователь осуществляет покупки.
![[Pasted image 20250112200521.png]]

Один из вопросов для информационной системы из которой собираем данные - Была ли система построена с учетом сбора данных?
#Качество_данных [[DAMA BOOK 13. Качество данных]]
Иногда случается так, что обладание собственной системой не лучше работы с внешним поставщиком.

# Интерфейс сбора и структура данных
## Интерфейсы
В число наиболее распространенных интерфейсов входят:
- реляционные БД;
- абстракция поверх системы - API;
- брокеры сообщений - аля Кафка;
- Сетевая файловая система или сегмент облачного хранилища, содержащие файлы;
- DWH, Data Lake;
- данные в HDFS (распределенная файловая система Hadoop для хранения файлов больших размеров с возможностью потокового доступа к информации), HBASE;
## Структура данных
Наиболее популярные:
- JSON из REST API;
- хорошо структурированные данные из реляционной БД;
- JSON из реляционной БД;
- полуструктурированные данные журнала;
- CSV и другие плоские файлы;
- потоковый вывод из брокера сообщений;
У каждого интерфейса свои достоинства и недостатки. Как правило данные структурированны в рамках своего приложения. Например нет надежды, что JSON файл будет везде иметь одинаковую структуру.

Автор советует уделять сбору и обработке данных достаточное внимание, без упрощений и усложнений.

[[АК2. Качество данных |какие ошибки с данными бывают]] 

Как правило входные наборы данных содержат проблемы с достоверностью и согласованностью, конвейеры их идентифицируют и очищают.

Необходимо очищать и проверять данные в системе, которая лучше всего подходит для этого.


# Инструменты преобразования и моделирования данных
Оба термина взаимосвязаны и взаимозаменяемы, но в этой книге автор их различает
## Преобразование
Широкое понятие, которому соответствует T в ETL. Может быть простым - преобразование метки времени из одного  часового пояса в другой. Также может быть сложная метрика создающая новую метрику из нескольких исходных столбцов, которая агрегируется и фильтруется с помощью бизнес-логики.
## Моделирование
Более конкретный тип преобразования данных. Модель структурирует и определяет данные в формате понятном и оптимизированном для анализа.

Для различных видов преобразований автор предпочитает различные инструменты. Например для передачи персональной инфы автор использует какие-то алгоритмы хэширования.

# Оркестровка рабочих процессов
По мере роста сложности и количества конвейеров данных важно своевременно внедрить платформу оркестровки рабочих процессов. Платформы управляют планированием и потоком задач в конвейере.
#Оркестровка - инструмент для планирования и управления зависимостями.
Почти все платформы оркестровки позволяют создавать DAG - directed acyclic graph. Направленный ациклический граф. Dag это представление набора задач, а не место, где определяется их логика.

![[Pasted image 20250112210846.png]]