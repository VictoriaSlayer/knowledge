https://www.youtube.com/watch?v=PXorzp9tWOo&ab_channel=Intellik
# Вводная
Первоначально был #ETL - данные выгружаются из системы-источника, обрабатываются в отдельной подсистеме, затем итоговый набор данных загружается в хранилище.
Потом придумали #ELT - данные загружаются в целевую систему с минимальными изменениями, вся обработка происходит в системе хранилище.
# ETL
Состоит из нескольких этапов:
![[Pasted image 20250107184010.png]]
OLTP - online transactional processing. Источники данных в которых хранятся сырые данные.
*ODS* -  operational data storage. Как правило прямая реплика всех данных которые есть в наших транзакционных системах. Делается, чтобы не отправлять запросы в транзакционную систему, которые могут её положить, а чтобы мы работали с репликой.
*Staging* - служит для расчета. Область подготовки данных. На этом слое данные преобразуются к структуре области детальных данных. Также происходит отбор инкремента исходных данных относительно уже загруженных в детальный слой.
В зависимости от архитектуры могут быть как и ODS, так и STG.
Если необходимо выполнить простой запрос, то обращаются к ODS. Если сложный, то к Stage.

*DDS* - Detailing Data Storage. Именно в этом слое хранятся все данные в том формате, который максимально удобен для анализа. Существует несколько парадигм как эти данные хранить. Автор рассматривает модель Кимбала.

*Data mart* - витрина под конкретную задачу.

Структура его хранилища:
OLTP - staging/ODS - DDS - Reporting data: DM/Analytic DM/ Files - конечный потребитель.
ETL как раз нужен для того, чтобы обрабатывать и передавать данные между слоями.

В случае ELT мы просто перегоняем данные до DDS без обработки.

# Хранилище данных по модели Кимбала
## Таблицы Измерений
*Таблицы измерений* - таблицы измерений предоставляют контекст для анализа бизнес-событий и отвечают на вопросы - кто, что, где, когда и т.д. У каждой таблицы есть уникальный первичный ключ. Этот ключ добавляется в качестве внешнего ключа в связанные таблицы фактов. Таблицы измерений как правило широкие денормализованные таблицы с множеством атрибутов.
Таблица измерений как правило денормализована. Чтобы Join было меньше и аналитик мог создавать более простые запросы.
### Виды таблиц измерений
Зависит от того, насколько гибко мы хотим отслеживать изменения.
В основном следующие виды:
0 - Остаются исходные значения.
1 - Новые значения перезаписывают старые. История изменений не хранится.
![[Pasted image 20250107213844.png]]
Поменяли департамент.

2 - новые значения добавляются отдельной строкой. Для отслеживания изменений появляется колонка актуальности записи.
![[Pasted image 20250107213918.png]]
3 - старые значения хранятся в отдельных колонках. Смотреть аналитику по старым и по новым ценам. 
![[Pasted image 20250107214009.png]]
мы точно знаем, что будет использоваться только одно значение и оно меняться не будет.

прочие - комбинации таблиц типа 1-3.

## Таблицы фактов
*Таблицы фактов* - содержат числовые метрики, связанные с каким-либо событием, которое нам необходимо отслеживать. В таблице фактов присутствует несколько типов ключей. Это могут быть как сырые, так и предрасчитанные метрики.
### Виды таблиц фактов
*Транзакционная* - строка в таблице соответствует определенному событию с определенными характеристиками в момент времени. 
![[Pasted image 20250107215053.png]]
Имеется событие информацию о которым мы отслеживаем. Для него грузим всю необходимую информацию (все, что ниже Pos Transaction). Ключи - это ключи к другим справочникам Date dimension, store (продажи) dimension и т.д.
*Периодические срезы* - строка в таблице показывает результат изменения определенных метрик за определенный период времени.
![[Pasted image 20250107222347.png]]
Любые аналитики складывают раз в месяц для анализа

*Накопительные срезы* - строка в таблице показывает результат некоторого бизнес процесса с определенным количеством этапов.
![[Pasted image 20250107222725.png]]
Используется редко, чтобы понять как процесс изменяется во времени. Например воронка продаж. Для каждого этапа ставится своя дата изменения, дата когда появились изменения, а дальше FK для связи с внешними таблицами.

*Первичный ключ* - ключ из оригинального источника - product_id и т.д. Добавляется в таблицу измерений.
*Суррогатный ключ* - ключ в хранилище данных. Однозначно идентифицирует сущность в конкретный модель времени. Часто описывается суффиксом_key. Например product_key. Добавляется в таблицу измерений.
Например хотим отслеживать изменение стоимости товара. И суррогатный ключ создается для айдишника товара, и создается его стоимость в течении времени.


## Этапы создания витрин
1. Выбрать бизнес-процесс.
2. Определить детализацию витрины (зерно, grain). Кимбалл рекомендует максимально детализированный уровень.
3. Определить измерения.
4. Определить факты.

## Стандартизация измерений
![[Pasted image 20250107223148.png]]
В нашей БД для каждой сущности создается одно стандартизированное измерение, которое можно агрегировать информацию из разных источников данных, транзакционных систем.
Информация о продукте может храниться во множестве систем. Всю эту инфу собирают и хранят в одной таблице. Все таблицы фактов по продажам продукта используют с единым справочником. И можно проводить анализ по интересующим нам срезам.
## Шина (матрица) данных
![[Pasted image 20250107223408.png]]
Один бп делится как правило на несколько более мелких. Но у нескольких мелких БП есть пересечения по нескольким измерениям.
Важно проговорить с бизнесом - какие процессы используются в бизнесе, и что мы хотим проанализировать.
Вверху таблица измерений. Внизу таблица фактов. После этого надо сделать таблицы по очереди.
## Матрица стейкхолдеров
![[Pasted image 20250107223659.png]]
## Проблемы с архитектурой Кимбала
Достаточно древняя - 2013 года.
Достаточно жесткая структура. Если гранулярность/декомпозиция поменялась, появилось новое измерение которое мы не предусмотрели, необходимо переделывать всю таблицу фактов и связанные измерения.
![[Pasted image 20250107225116.png]]
Дублирование данных в SCD2 - slowly changed dimensions. Разные атрибуты могут обновляться с разной скоростью, а добавлять приходится всю цепочку целиком.
![[Pasted image 20250107225155.png]]
Сроки и скорость разработки существенно возрастают при добавлении новых/производных сущностей.


# Другие подходы
Подход Кимбалла считают более водопадным. Другие подходы более гибкие, но они сложнее
## Data Vault
Принципа нормально не понял, объяснение крайне быстрое. 
Если у Кимбала модель один ко многим, то здесь многие ко многим, и нужна отдельная таблица - Link в качестве справочника, что с чем связывать.
Сущности разделяются на хабы (хранят первичные ключи) и спутники (информация о сущности, причем спутников может быть несколько в зависимости от задачи). Связи хранятся в табличках Link объединяющих релевантные связи.

![[Pasted image 20250107225534.png]]
## Якорная модель
![[Pasted image 20250108014946.png]]
В якорной модели предлагается максимальная нормализация данных. Для каждой сущности создается отдельная таблица и хранятся все данные.
Всего для 5 сущностей выше создается 30 таблиц.

# Процесс создания витрины
1. Спланировать какие измерения и таблицы фактов требуются.
2. Описать модель данных и написать запросы для таблиц. СОздать таблицы.
3. Построить потоки для загрузки таблиц измерений.
4. Построить потоки для загрузки таблиц фактов.

Как может выглядеть документация для создания витрины
![[Pasted image 20250108015513.png]]
Source - из какой системы, из какой таблицы, название поля, тип поля, етл правила.

Хорошие практики по таблицам фактов и измерений:
называть их очевидно - dimension, fact. Dim_customers, fct_sales.
![[Pasted image 20250108021656.png]]
Для каждой таблицы колонки с мета информацией (вторая половина каждой таблицы):
- дата начала актуальности записи;
- дата окончания актуальности записи;
- активна запись на текущий момент или нет;
- дата создания записи;
- дата обновления записи;
- версия;
- обновление на стороне источника;

Отдельно создается таблица с расчетом всех дат - dim_date

Алгоритм при появлении новых полей в выгружаемой таблице. Проще смотреть алгоритм работы на ютубе.
![[Pasted image 20250108021850.png]]Отдельно у него прописан алгоритм загрузки фактов.
