# Общая часть
Управление данными усложняется из-за датафикации.
Датафикация - превращение аспектов в жизни в данные и их дальнейшее использование для создания ценности.
Автор прогнозирует, что в дальнейшем существующие архитектуры не смогут масштабироваться и нужна будет новая стратегия обработки данных.

Технологические тенденции формируют ландшафт данных. Скорость доставки ПО растет с появлением новых методологий за счет увеличения сложности данных. 

По автору - существуют:
- централизованное управление данными;
- местное управление данными;
То как я понимаю, автор подводит к мысли, что архитектура данных должна зависеть от общей архитектуры структуры. Если архитектура распределенная, то первый вариант может оказаться не самым удобным.
# Управление данными
Управление данными - разработка, выполнение и контроль планов, политик, программ и практик, которые доставляют, контролируют, защищают и повышают ценность данных и информационных активов на протяжении их жизненного цикла.

## Виды управления данными
Автор выбрал только те аспекты, которые посчитал нужными:
- *архитектура данных* - мастер-план данных, позволяет шире взглянуть на вашу архитектуру, включая схемы, эталонные архитектуры, видение перспективы и зависимости. Управление этими вещами позволяет принимать решения;
- *руководство данными* - реализация и обеспечение полномочий, а также контроль над управлением данными;
- *моделирование и проектирование данных* - структурирование и представление данных в определенном контексте и конкретных системах. Обнаружение, проектирование и анализ требований к данным - часть этой дисциплины;
- *управление БД, хранение данных и операции с ними* - управление проектом БД, правильной реализации и поддержки с целью увеличения ценности данных;
- *управление безопасностью данных* - все дисциплины и действия обеспечивающие безопасную аутентификацию, авторизацию и доступ к данным;
- *интеграция и согласованность данных* - все дисциплины и действия по транспортировке, сбору, объединению и трансформации данных для эффективного их перемещения из одного контекста в другой.
  *Согласованность данных* - возможность взаимодействий путем вызова функций или передачи данных между различными приложениями способами, не требующими знания характеристик приложения.
  *Интеграция данных* - объединение данных из различных источников в единое представление. Часто взаимосвязан с репликацией и ETL.
- *Управление справочными и основными данными* - обеспечение доступности, точности, безопасности, прозрачности и надежности данных;
- *Управление жизненным циклом данных* - относится к процессу работы с данными в течении жизненного цикла данных. От создания и первоначального хранения, до момента их устаревания и удаления;
- *Управление метаданными* - управление всей информацией, которая классифицирует и описывает данные. Метаданные позволяют сделать данные понятными, безопасными и готовыми к интеграции, используются для обеспечения качества;
- *Управление качеством данных* - гарантия пригодности данных к использованию;
- *Управление хранением данных, бизнес-аналитикой и продвинутой аналитикой* - помогают понять как действуют бизнес-законы и принимать решения.
Автор утверждает, что метаданные разбросаны среди множества инструментов, разнообразны и согласованность метаданных - способность различных ИС обмениваться описательной информацией о данных недооценена и об этом не так много информации.

По автору - архитектура централизованной платформы может потерпеть неудачи из-за быстрого развития технологий:
- облачные вычисления;
- аналитика;
- новые методы разработки ПО;
- монетизация данных;
- принятие решений REALTIME;

# Виды проблем с данными
## Аналитика фрагментирует ландшафт данных
Продвинутая аналитика существенно влияет на ландшафт данных. Чем больше данных, тем выше число вариантов и возможностей.
Тренд ускоривший продвинутую аналитику - открытый исходный код. Высококачественные проекты с открытым исходным кодом становятся стандартом.
Открытый исходный код привел к созданию специализированных баз - Cassandra, Redis, MongoDB и т.д. В результате повысилась эффективность создания и разработки современных решений. Сложные задачи теперь легко решать с помощью узкоспециализированной БД. Нет необходимости использовать устаревшую логику реляционной БД и сложную прикладную логику.

Разнообразие и рост продвинутой аналитики привели к двум проблемам:
- быстрое разрастание;
- увеличение объема данных;

### Быстрое разрастание
По мере разрастания одни и те же данные распределяются по множеству приложений и БД. DWH использующее систему управления реляционными базами данных не способно выполнять сложный анализ соц. сетей. Для этих целей лучше использовать графовую БД.

Это приводит к необходимости регулярного экспорта данных в другие БД. А это может привести к тому, что если данные разбросаны по организации, то найти и оценить их происхождение трудно. Что усложняет управление данными, ведь они могут распределяться и вне централизованной платформы.

### Увеличение объема данных
Развитие аналитических методов ускоряет рост объема данных. Соотношение чтения и записи значительно меняется. Приходится оптимизировать данные для чтения. Чтобы избавить БД от оптимизации данные приходится дублировать, чтобы применять к ним свои UseCase - дополнительно очищать и т.д.

## Скорость доставки ПО увеличивается
Программные сервисы составляют основу бизнеса, что означает, что нужно быстро выпускать обновления.
Ожидается, что гибкость системы возрастет, если приложения превратится в мелкие сервисы, решающие узкоспециализированные задачи. Отсюда растут ноги у:
- микросервисы;
- контейнеры;
- кибернетес;
- предметно-ориентированное проектирование;
- бессерверные вычисления;
Эта эволюция разработки также требует улучшенного контроля данных.
Преобразование монолита в распределенное приложение создает множество проблем связанных с управлением данными. Различным командам приходится переводить свои уникальные хранилища на архитектуры, где объекты данных распределены. Это создает следующие проблемы:
- увеличивающееся количество сетевых взаимодействий;
- необходимость синхронизация копий данных для чтения;
- обеспечение согласованности;
- ссылочной целостности;
- и т.д.;
## Сети становятся быстрее
Из-за увеличения объемов передачи по сети, продвигаются технологии:
- SaaS - software as a service;
- MLaaS - machine learning as a service;
## Вопросы безопасности
По мере того, как компании будут совершать ошибки и пересекать границы этических норм государство будет все больше регулировать эту историю. Здесь тоже в будущем будет большой снежный ком.

## Интеграция различных ИС
Существует четкое разделение по функционалу ИС:
- обработка транзакций;
- аналитические приложения;

Так происходит потому что мощности ИС по обработке транзакций не хватает для аналитики.
Лучшей практикой в этом случае считалось разделение стратегии на две части:
- обслуживание транзакций, сохранение аналитических данных;
- обработка больших данных;
Однако сейчас эти разделения все менее очевидны.
В будущем аналитика построенная вокруг прогнозирования будет тесно взаимодействовать как с транзакционными так и с аналитическими системами. 
Эта тенденция будет требовать другой архитектуры интеграции, объединяющие операционные и аналитические системы, которые работают на разных скоростях.
## Экосистемная архитектура
Единая экосистема предприятия все чаще интегрирует свои бизнес-функции и услуги со сторонними организациями для монетизации.
Как следствие данные становятся децентрализованными, что приводит к затруднению интеграции и управлению.

# Предприятия обременены устаревшими архитектурами данных
Одна из самых больших проблем - получение выгоды от существующих DWH.
Большинство архитектур используют монолитную структуру - DWH или озеро данных.

## Проблемы DWH
- Унификация корпоративных данных занимает много лет;
- В различных ИС и системах значения данных разнятся. Атрибуты данных могут иметь одинаковые имена, но разные значения и определения. Вариант решения - либо много вариантов данных, либо принятие противоречий и различий. Если мы сделаем единый контекст, то скорее всего для всех он будет бессмысленный;
- DWH является интеграционной БД. Изменения следует вносить осторожно, т.к. может вызвать эффект ряби для многих систем;
- Высокая сложность DWH и управление одной группой плохо сказывается на гибкости. Люди перестают понимать архитектуру и обходные пути для решения проблем;
  Большой ком грязи - хаотично устроенные, раскидистые, неряшливые джунгли из спагетти-кода. Монолитная, трудная для понимания и обслуживания архитектура, тесно связанная из-за зависимостей с другими компонентами.
  ![[Pasted image 20250102022508.png]]
- DWH тесно связаны с выбранным базовым решением или технологией;
- Качество данных в DWH;
- Кому принадлежат данные в хранилищах;
- Кто несет ответственность, если исходные ИС доставляют поврежденные данные;
## Озера данных
По мере роста объемов данных и необходимости более быстрого анализа начали работать над другими концепциями. Озера данных возникли как альтернатива для доступа к большим объемам сырых, необработанных данных. Потребитель сам решает как использовать, преобразовывать и интегрировать данные.

Озеро как и DWH считается монолитным, оно отличается от DWH тем, что хранит данные до преобразования, очищения и структурирования. 
Поэтому схемы часто определяются при чтении данных. В хранилищах же структура предопределенная и фиксированная.
DWH как правило используют реляционные базы данных, а озеро распределенные или NoSQL.

Озера данных содержат несколько форматов данных:
- структурированные;
- полуструктурированные;
- неструктурированные;

Минусы озера:
- несмотря на то, что данные собираются в сыром виде, для них требуется предварительная обработка, чтобы данные соответствовали контексту. В этой ситуации озера объединяют с DWH;
- огромная сложность, проблемы с обслуживанием и общие зависимости;
- в озере хранится сложная совокупность различных представлений;
- в озерах могут храниться искусственные данные которые используются для обучения моделей, что в свою очередь может нести операционные риски для бизнеса;
![[Pasted image 20250102121723.png]]


По автору - централизованный подход при управлении данными означает, что все живут в единой терминологии. И тут есть негативный эффект - убирая специалистов по данным из бизнес-областей мы лишаемся бизнес-идей и творческих подходов. Команды вынуждены постоянно взаимодействовать друг с другом. Сейчас появилась новая парадигма - предметно-ориентированное проектирование. В чем он заключается хз.

Независимо от любого архитектурного стиля моделирования - Инмон, Кимбал или хранилище данных, все можно использовать в зависимости от варианта использования.

Для решения всех перечисленных проблем необходима масштабируемая архитектура: типовая и предметно-ориентированная с набором схем, проектов, принципов, моделей, лучших практик.
По сути эта архитектура сближающая все области управления данными. Эта архитектура дает контроль, гибкость и упрощает работу команд, позволяя работать без помощи центральной группы и при этом обеспечивая гибкость при решениях.